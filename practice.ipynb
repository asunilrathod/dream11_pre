{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File JSON_DATA\\gloucestershire-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\nottinghamshire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-lancashire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-kent-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-worcestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\durham-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\essex-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\gloucestershire-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-glamorgan-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\middlesex-vs-gloucestershire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-birmingham-bears-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\somerset-vs-sussex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-hampshire-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\worcestershire-vs-derbyshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\derbyshire-vs-durham-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\glamorgan-vs-somerset-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\hampshire-vs-essex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\kent-vs-surrey-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\lancashire-vs-northamptonshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-middlesex-south-group.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-leicestershire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\yorkshire-vs-nottinghamshire-north-group.json already exists. Skipping...\n",
      "File JSON_DATA\\surrey-vs-durham-1st-quarter-final.json already exists. Skipping...\n",
      "File JSON_DATA\\sussex-vs-lancashire-2nd-quarter-final.json already exists. Skipping...\n",
      "File JSON_DATA\\northamptonshire-vs-somerset-3rd-quarter-final.json already exists. Skipping...\n",
      "File JSON_DATA\\birmingham-bears-vs-gloucestershire-4th-quarter-final.json already exists. Skipping...\n",
      "File JSON_DATA\\tba-vs-tba-1st-semi-final.json already exists. Skipping...\n",
      "File JSON_DATA\\tba-vs-tba-2nd-semi-final.json already exists. Skipping...\n",
      "File JSON_DATA\\tba-vs-tba-final.json already exists. Skipping...\n",
      "File JSON_DATA\\leicestershire-vs-yorkshire-north-group.json already exists. Skipping...\n",
      "JSON extraction and saving process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_data_from_api(api_url, headers=None, params=None):\n",
    "    try:\n",
    "        response = requests.get(api_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        content_type = response.headers.get('Content-Type')\n",
    "        if 'application/json' in content_type:\n",
    "            return response.json(), None\n",
    "        else:\n",
    "            return None, response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_json_after_next_data_tag(file_content):\n",
    "    try:\n",
    "        json_start = file_content.find('_NEXT_DATA__\" type=\"application/json\">') + len('_NEXT_DATA__\" type=\"application/json\">')\n",
    "        if json_start == -1:\n",
    "            raise ValueError(\"Start marker not found in the file content\")\n",
    "        json_content = file_content[json_start:]\n",
    "        json_end = json_content.find('</script>')\n",
    "        if (json_end == -1):\n",
    "            raise ValueError(\"End marker not found in the file content\")\n",
    "        json_content = json_content[:json_end].strip()\n",
    "        json_data = json.loads(json_content)\n",
    "        return json_data, json_content\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting JSON: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def save_json_to_file(json_content, output_file):\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(json_content)\n",
    "        print(f\"JSON content successfully saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving JSON to file: {e}\")\n",
    "\n",
    "# Load Excel file and create the JSON_DATA directory\n",
    "excel_file_path = \"C:\\\\Users\\\\Sunil\\\\OneDrive\\\\Desktop\\\\Crickbuzz_data\\\\API_EXTRACTION\\\\Recent_Matches_with_API_Name.xlsx\"\n",
    "output_folder = \"JSON_DATA\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    api_url = row['final_api']\n",
    "    file_name = row['api_name']\n",
    "    json_output_file = os.path.join(output_folder, f\"{file_name}.json\")\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(json_output_file):\n",
    "        print(f\"File {json_output_file} already exists. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    json_data, html_content = fetch_data_from_api(api_url)\n",
    "    \n",
    "    if html_content:\n",
    "        json_data, json_content = extract_json_after_next_data_tag(html_content)\n",
    "        if json_content:\n",
    "            save_json_to_file(json_content, json_output_file)\n",
    "    else:\n",
    "        if json_data:\n",
    "            json_content = json.dumps(json_data, indent=4)\n",
    "            save_json_to_file(json_content, json_output_file)\n",
    "\n",
    "print(\"JSON extraction and saving process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunil\\AppData\\Local\\Temp\\ipykernel_22516\\3650371768.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(all_dataframes, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      seriesId  matchId  playerId playerLongName playerBattingStyles  \\\n",
      "0      1410370  1410479     46597      Moeen Ali             ['lhb']   \n",
      "1      1410370  1410479     65368    Alex Davies             ['rhb']   \n",
      "2      1410370  1410479    104560    Dan Mousley             ['lhb']   \n",
      "3      1410370  1410479     67482       Sam Hain             ['rhb']   \n",
      "4      1410370  1410479    105968  Jacob Bethell             ['lhb']   \n",
      "...        ...      ...       ...            ...                 ...   \n",
      "2580   1410370  1410375    102629  Matthew Revis             ['rhb']   \n",
      "2581   1410370  1410375     71499       Dom Bess             ['rhb']   \n",
      "2582   1410370  1410375    102861   Jafer Chohan             ['rhb']   \n",
      "2583   1410370  1410375    102375  Dominic Leech             ['rhb']   \n",
      "2584   1410370  1410375     88645   Dan Moriarty             ['lhb']   \n",
      "\n",
      "     playerRoleType battedType  runs  balls  minutes  ...  ballOversUnique  \\\n",
      "0                 P        yes  59.0   32.0     37.0  ...             9.04   \n",
      "1                 C        yes  14.0   14.0     16.0  ...             4.01   \n",
      "2                 P        yes  60.0   44.0     62.0  ...              NaN   \n",
      "3                 P        yes  52.0   30.0     41.0  ...              NaN   \n",
      "4                 P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "...             ...        ...   ...    ...      ...  ...              ...   \n",
      "2580              P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "2581              P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "2582              P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "2583              P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "2584              P        DNB   NaN    NaN      NaN  ...              NaN   \n",
      "\n",
      "      ballTotalRuns  ballBatsmanRuns  videos  images currentType  \\\n",
      "0              87.0              0.0      []      []         NaN   \n",
      "1              21.0              0.0      []      []         NaN   \n",
      "2               NaN              NaN      []      []         NaN   \n",
      "3               NaN              NaN      []      []         NaN   \n",
      "4               NaN              NaN      []      []         NaN   \n",
      "...             ...              ...     ...     ...         ...   \n",
      "2580            NaN              NaN      []      []         NaN   \n",
      "2581            NaN              NaN      []      []         NaN   \n",
      "2582            NaN              NaN      []      []         NaN   \n",
      "2583            NaN              NaN      []      []         NaN   \n",
      "2584            NaN              NaN      []      []         NaN   \n",
      "\n",
      "     dismissalType.1 bowlerId  bowlerLongName  bowlingStyles  \n",
      "0                1.0  83427.0       Pat Brown        ['rfm']  \n",
      "1                1.0  51498.0   Mohammad Amir        ['lfm']  \n",
      "2               12.0      NaN             NaN            NaN  \n",
      "3               12.0      NaN             NaN            NaN  \n",
      "4                NaN      NaN             NaN            NaN  \n",
      "...              ...      ...             ...            ...  \n",
      "2580             NaN      NaN             NaN            NaN  \n",
      "2581             NaN      NaN             NaN            NaN  \n",
      "2582             NaN      NaN             NaN            NaN  \n",
      "2583             NaN      NaN             NaN            NaN  \n",
      "2584             NaN      NaN             NaN            NaN  \n",
      "\n",
      "[2585 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Path to the folder containing JSON files\n",
    "json_folder_path = 'JSON_DATA'\n",
    "\n",
    "# List to hold all DataFrames\n",
    "all_dataframes = []\n",
    "\n",
    "# Iterate through all JSON files in the folder\n",
    "for json_file in os.listdir(json_folder_path):\n",
    "    if json_file.endswith('.json'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(json_folder_path, json_file)\n",
    "        \n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract the relevant details\n",
    "        series_id = data.get('query', {}).get('seriesId')\n",
    "        match_id = data.get('query', {}).get('matchId')\n",
    "        innings = data.get('props', {}).get('appPageProps', {}).get('data', {}).get('content', {}).get('innings', [])\n",
    "        \n",
    "        # Create an empty list to store all batsman details for this JSON file\n",
    "        all_batsmen = []\n",
    "        \n",
    "        # Iterate over each inning in the innings list\n",
    "        for inning in innings:\n",
    "            # Check if 'inningBatsmen' is a key in the inning dictionary\n",
    "            if 'inningBatsmen' in inning:\n",
    "                batsmen = inning['inningBatsmen']\n",
    "                # Add seriesId and matchId to each batsman's dictionary\n",
    "                for batsman in batsmen:\n",
    "                    batsman['seriesId'] = series_id\n",
    "                    batsman['matchId'] = match_id\n",
    "                # Extend the all_batsmen list with details from the current inning\n",
    "                all_batsmen.extend(batsmen)\n",
    "        \n",
    "        if all_batsmen:\n",
    "            # Convert the details to a pandas DataFrame\n",
    "            df = pd.DataFrame(all_batsmen)\n",
    "            \n",
    "            # Extract player details into separate columns if the key exists\n",
    "            if 'player' in df.columns:\n",
    "                df['playerId'] = df['player'].apply(lambda x: x.get('id') if x else None)\n",
    "                df['playerLongName'] = df['player'].apply(lambda x: x.get('longName') if x else None)\n",
    "                df['playerBattingStyles'] = df['player'].apply(lambda x: x.get('battingStyles') if x else None)\n",
    "                df = df.drop(columns=['player'])\n",
    "            \n",
    "            # Extract bowler details into separate columns if the key exists\n",
    "            if 'dismissalBowler' in df.columns:\n",
    "                df['bowlerId'] = df['dismissalBowler'].apply(lambda x: x.get('id') if x else None)\n",
    "                df['bowlerLongName'] = df['dismissalBowler'].apply(lambda x: x.get('longName') if x else None)\n",
    "                df['bowlingStyles'] = df['dismissalBowler'].apply(lambda x: x.get('bowlingStyles') if x else None)\n",
    "                df = df.drop(columns=['dismissalBowler'])\n",
    "            \n",
    "            # Reorder the columns to ensure seriesId and matchId are first\n",
    "            # and bowler details are after dismissalType\n",
    "            columns_order = ['seriesId', 'matchId', 'playerId', 'playerLongName', 'playerBattingStyles'] + \\\n",
    "                            [col for col in df.columns if col not in ['seriesId', 'matchId', 'playerId', 'playerLongName', 'playerBattingStyles', 'bowlerId', 'bowlerLongName', 'bowlingStyles']] + \\\n",
    "                            ['dismissalType', 'bowlerId', 'bowlerLongName', 'bowlingStyles']\n",
    "            df = df[columns_order]\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            all_dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame if there is data\n",
    "if all_dataframes:\n",
    "    final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame to an Excel file\n",
    "    final_df.to_excel('all_batsmen_details.xlsx', index=False)\n",
    "\n",
    "    # Load the Excel file to verify its content\n",
    "    df_excel = pd.read_excel('all_batsmen_details.xlsx')\n",
    "    print(df_excel)\n",
    "else:\n",
    "    print(\"No valid batsman data found in the JSON files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely convert string representation of list to actual list and extract the first element\n",
    "def extract_first_element(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # Convert string representation of list to actual list\n",
    "            value_list = ast.literal_eval(value)\n",
    "            if isinstance(value_list, list) and len(value_list) > 0:\n",
    "                return value_list[0]\n",
    "        except (ValueError, SyntaxError):\n",
    "            # If conversion fails, just return the value\n",
    "            return value\n",
    "    return value\n",
    "\n",
    "# Apply the function to the relevant columns\n",
    "df_excel['playerBattingStyles'] = df_excel['playerBattingStyles'].apply(extract_first_element)\n",
    "df_excel['bowlingStyles'] = df_excel['bowlingStyles'].apply(extract_first_element)\n",
    "\n",
    "# Drop the specified columns\n",
    "df_excel = df_excel.drop(columns=['dismissalBatsman', 'dismissalFielders', 'dismissalText', 'dismissalComment', 'fowBalls', 'ballOversActual', 'ballOversUnique', 'ballTotalRuns', 'ballBatsmanRuns', 'videos', 'images', 'currentType', 'dismissalType'])\n",
    "\n",
    "# Optionally, save the DataFrame to a new CSV file\n",
    "df_excel.to_csv('all_batsmen_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      seriesId  matchId bowlerIds bowlerLongNames  overNumber  overRuns  \\\n",
      "0      1410370  1410479     51498   Mohammad Amir           1         2   \n",
      "1      1410370  1410479     71425    Alex Thomson           2         2   \n",
      "2      1410370  1410479     81537    Zak Chappell           3        10   \n",
      "3      1410370  1410479     83427       Pat Brown           4         7   \n",
      "4      1410370  1410479     51498   Mohammad Amir           5        10   \n",
      "...        ...      ...       ...             ...         ...       ...   \n",
      "4314   1410370  1410375     61941    Hayden Walsh           8         5   \n",
      "4315   1410370  1410375     53162       Josh Cobb           9        11   \n",
      "4316   1410370  1410375     61941    Hayden Walsh          10         9   \n",
      "4317   1410370  1410375     65499      Tom Taylor          11        14   \n",
      "4318   1410370  1410375     61941    Hayden Walsh          12         9   \n",
      "\n",
      "      overWickets  isComplete  totalBalls  totalRuns  totalWickets  \\\n",
      "0               0        True           6          2             0   \n",
      "1               0        True          12          4             0   \n",
      "2               0        True          18         14             0   \n",
      "3               0        True          24         21             0   \n",
      "4               1        True          30         31             1   \n",
      "...           ...         ...         ...        ...           ...   \n",
      "4314            0        True          48         61             2   \n",
      "4315            0        True          54         72             2   \n",
      "4316            0        True          60         81             2   \n",
      "4317            0        True          66         95             2   \n",
      "4318            0       False          66        104             2   \n",
      "\n",
      "      overRunRate  requiredRunRate  requiredRuns  remainingBalls  predictions  \\\n",
      "0            2.00             0.00             0             114          NaN   \n",
      "1            2.00             0.00             0             108          NaN   \n",
      "2            4.66             0.00             0             102          NaN   \n",
      "3            5.25             0.00             0              96          NaN   \n",
      "4            6.20             0.00             0              90          NaN   \n",
      "...           ...              ...           ...             ...          ...   \n",
      "4314         7.62             3.41            41              72          NaN   \n",
      "4315         8.00             2.72            30              66          NaN   \n",
      "4316         8.10             2.09            21              60          NaN   \n",
      "4317         8.63             0.77             7              54          NaN   \n",
      "4318         9.45             0.00             0              50          NaN   \n",
      "\n",
      "                                                  balls events  \n",
      "0     [{'_uid': 46315830, 'id': 46315830, 'inningNum...     []  \n",
      "1                                                    []     []  \n",
      "2                                                    []     []  \n",
      "3                                                    []     []  \n",
      "4                                                    []     []  \n",
      "...                                                 ...    ...  \n",
      "4314                                                 []     []  \n",
      "4315                                                 []     []  \n",
      "4316                                                 []     []  \n",
      "4317                                                 []     []  \n",
      "4318                                                 []     []  \n",
      "\n",
      "[4319 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Path to the folder containing JSON files\n",
    "json_folder_path = 'JSON_DATA'\n",
    "\n",
    "# List to hold all DataFrames\n",
    "all_dataframes = []\n",
    "\n",
    "# Function to extract bowler details into separate columns\n",
    "def extract_bowler_info(bowlers_list, key):\n",
    "    if bowlers_list and isinstance(bowlers_list, list):\n",
    "        return ', '.join([str(bowler.get(key)) for bowler in bowlers_list if bowler.get(key) is not None])\n",
    "    return None\n",
    "\n",
    "# Iterate through all JSON files in the folder\n",
    "for json_file in os.listdir(json_folder_path):\n",
    "    if json_file.endswith('.json'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(json_folder_path, json_file)\n",
    "        \n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract the relevant details\n",
    "        series_id = data.get('query', {}).get('seriesId')\n",
    "        match_id = data.get('query', {}).get('matchId')\n",
    "        innings = data.get('props', {}).get('appPageProps', {}).get('data', {}).get('content', {}).get('innings', [])\n",
    "        \n",
    "        # Create an empty list to store all inningOvers details for this JSON file\n",
    "        all_inningOvers = []\n",
    "        \n",
    "        # Iterate over each inning in the innings list\n",
    "        for inning in innings:\n",
    "            # Check if 'inningOvers' is a key in the inning dictionary\n",
    "            if 'inningOvers' in inning:\n",
    "                inningOvers = inning['inningOvers']\n",
    "                # Add seriesId and matchId to each over's dictionary\n",
    "                for over in inningOvers:\n",
    "                    over['seriesId'] = series_id\n",
    "                    over['matchId'] = match_id\n",
    "                # Extend the all_inningOvers list with details from the current inning\n",
    "                all_inningOvers.extend(inningOvers)\n",
    "        \n",
    "        if all_inningOvers:\n",
    "            # Convert the details to a pandas DataFrame\n",
    "            df = pd.DataFrame(all_inningOvers)\n",
    "            \n",
    "            # Add bowlerId and bowlerLongName columns as strings\n",
    "            if 'bowlers' in df.columns:\n",
    "                df['bowlerIds'] = df['bowlers'].apply(lambda x: extract_bowler_info(x, 'id'))\n",
    "                df['bowlerLongNames'] = df['bowlers'].apply(lambda x: extract_bowler_info(x, 'longName'))\n",
    "                # Drop the original 'bowlers' column\n",
    "                df = df.drop(columns=['bowlers'])\n",
    "            \n",
    "            # Reorder the columns to ensure seriesId, matchId, bowlerIds, and bowlerLongNames are first\n",
    "            columns_order = ['seriesId', 'matchId', 'bowlerIds', 'bowlerLongNames'] + \\\n",
    "                            [col for col in df.columns if col not in ['seriesId', 'matchId', 'bowlerIds', 'bowlerLongNames']]\n",
    "            df = df[columns_order]\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            all_dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame if there is data\n",
    "if all_dataframes:\n",
    "    final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    final_df.to_csv('all_bowlers.csv', index=False)\n",
    "\n",
    "    # Load the CSV to verify its content\n",
    "    df_csv = pd.read_csv('all_bowlers.csv')\n",
    "    print(df_csv)\n",
    "else:\n",
    "    print(\"No valid bowler data found in the JSON files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_csv\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_csv' is not defined"
     ]
    }
   ],
   "source": [
    "df_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
